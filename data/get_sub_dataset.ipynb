{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共 17 个子库: BMLrub ACCAD CMU MPIHDM05 EyesJapanDataset KIT EKUT MPImosh TCDhandMocap DFaust67 MPILimits SFU TotalCapture HumanEva SSMsynced BMLmovi Transitionsmocap\n"
     ]
    }
   ],
   "source": [
    "import json, pathlib, collections\n",
    "babel_root = pathlib.Path('./babel_v1.0_release')\n",
    "names = collections.Counter()\n",
    "\n",
    "for split in ['train','val','test','extra_train','extra_val']:\n",
    "    data = json.load(open(babel_root/f'{split}.json'))\n",
    "    for seq in data.values():\n",
    "        ds_name = pathlib.Path(seq['feat_p']).parts[0]   # e.g. 'ACCAD'\n",
    "        names[ds_name] += 1\n",
    "\n",
    "print('共 %d 个子库:'%len(names), *names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read from BABEL root: D:\\MotionPretrain\\data\\babel_v1.0_release\n",
      "Processing file: babel_v1.0_release\\train.json\n",
      "Processing file: babel_v1.0_release\\val.json\n",
      "Processing file: babel_v1.0_release\\test.json\n",
      "Processing file: babel_v1.0_release\\extra_train.json\n",
      "Processing file: babel_v1.0_release\\extra_val.json\n",
      "\n",
      "--- BABEL Dataset Statistics (FPS Assumed: 30.0) ---\n",
      "Found 17 unique sub-datasets:\n",
      "Sub-dataset               | Sample Count    | Total Frames (Est.) \n",
      "------------------------- | --------------- | --------------------\n",
      "ACCAD                     | 386             | 72577               \n",
      "BMLmovi                   | 2812            | 477086              \n",
      "BMLrub                    | 5177            | 1597157             \n",
      "CMU                       | 3319            | 1634353             \n",
      "DFaust67                  | 199             | 31523               \n",
      "EKUT                      | 548             | 86559               \n",
      "EyesJapanDataset          | 1273            | 1111422             \n",
      "HumanEva                  | 41              | 23026               \n",
      "KIT                       | 6666            | 1945939             \n",
      "MPIHDM05                  | 378             | 461359              \n",
      "MPILimits                 | 60              | 64376               \n",
      "MPImosh                   | 126             | 50220               \n",
      "SFU                       | 74              | 44059               \n",
      "SSMsynced                 | 49              | 5083                \n",
      "TCDhandMocap              | 99              | 22710               \n",
      "TotalCapture              | 57              | 114688              \n",
      "Transitionsmocap          | 185             | 45741               \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import collections\n",
    "\n",
    "babel_root = pathlib.Path('./babel_v1.0_release')  # Make sure this path is correct\n",
    "ASSUMED_FPS = 30.0  # Based on BABEL paper's normalization statement\n",
    "\n",
    "sample_counts = collections.Counter()\n",
    "frame_counts = collections.Counter()\n",
    "\n",
    "print(f\"Attempting to read from BABEL root: {babel_root.resolve()}\")\n",
    "\n",
    "if not babel_root.exists():\n",
    "    print(f\"Error: BABEL root directory '{babel_root}' does not exist. Please check the path.\")\n",
    "else:\n",
    "    splits_processed = 0\n",
    "    for split in ['train', 'val', 'test', 'extra_train', 'extra_val']:\n",
    "        json_file_path = babel_root / f'{split}.json'\n",
    "\n",
    "        if not json_file_path.exists():\n",
    "            print(f\"Warning: File '{json_file_path}' not found. Skipping this split.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing file: {json_file_path}\")\n",
    "        splits_processed += 1\n",
    "        try:\n",
    "            with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            if not isinstance(data, dict):\n",
    "                print(f\"Warning: Data in '{json_file_path}' is not a dictionary as expected. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            for seq_id, seq_info in data.items():\n",
    "                if not isinstance(seq_info, dict):\n",
    "                    print(f\"Warning: Sequence entry for ID '{seq_id}' in '{json_file_path}' is not a dictionary. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # 1. Extract sub-dataset name\n",
    "                ds_name = \"Unknown_Dataset\" # Default\n",
    "                if 'feat_p' in seq_info and isinstance(seq_info['feat_p'], str) and seq_info['feat_p']:\n",
    "                    try:\n",
    "                        # e.g., 'BMLrub/BioMotionLab_NTroje/rub055/...' -> 'BMLrub'\n",
    "                        ds_name = pathlib.Path(seq_info['feat_p']).parts[0]\n",
    "                    except IndexError:\n",
    "                        print(f\"Warning: Could not determine dataset name from 'feat_p': '{seq_info['feat_p']}' for seq ID '{seq_id}'. Using '{ds_name}'.\")\n",
    "                else:\n",
    "                    print(f\"Warning: 'feat_p' key missing or invalid for seq ID '{seq_id}'. Using '{ds_name}'.\")\n",
    "\n",
    "                # 2. Count samples\n",
    "                sample_counts[ds_name] += 1\n",
    "\n",
    "                # 3. Calculate and count frames\n",
    "                if 'dur' in seq_info:\n",
    "                    try:\n",
    "                        duration = float(seq_info['dur'])\n",
    "                        frames_in_sequence = int(round(duration * ASSUMED_FPS))\n",
    "                        frame_counts[ds_name] += frames_in_sequence\n",
    "                    except (ValueError, TypeError):\n",
    "                        print(f\"Warning: Could not parse 'dur': '{seq_info['dur']}' as float for seq ID '{seq_id}' from '{ds_name}'. Frame count not added for this sequence.\")\n",
    "                else:\n",
    "                    print(f\"Warning: 'dur' key not found for seq ID '{seq_id}' from '{ds_name}'. Frame count not added for this sequence.\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error: Could not decode JSON from '{json_file_path}': {e}. Skipping this split.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while processing '{json_file_path}': {e}\")\n",
    "\n",
    "    if splits_processed > 0:\n",
    "        print(f'\\n--- BABEL Dataset Statistics (FPS Assumed: {ASSUMED_FPS}) ---')\n",
    "        if not sample_counts:\n",
    "            print(\"No samples were successfully processed from any sub-dataset.\")\n",
    "        else:\n",
    "            print(f'Found {len(sample_counts)} unique sub-datasets:')\n",
    "            print(f\"{'Sub-dataset':<25} | {'Sample Count':<15} | {'Total Frames (Est.)':<20}\")\n",
    "            print(f\"{'-'*25} | {'-'*15} | {'-'*20}\")\n",
    "            for ds_name in sorted(sample_counts.keys()):\n",
    "                samples = sample_counts[ds_name]\n",
    "                frames = frame_counts[ds_name] # frame_counts will have the same keys\n",
    "                print(f\"{ds_name:<25} | {samples:<15} | {frames:<20}\")\n",
    "    elif not babel_root.exists():\n",
    "        pass # Error already printed at the beginning\n",
    "    else:\n",
    "        print(\"No split files ('train.json', 'val.json', etc.) were found or processed in the specified BABEL directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Alphapose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
